{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3f01d7-3204-488f-97a7-81624cea6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel as C\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Problem setup\n",
    "L_x, L_y = 1.0, 1.0  # Domain size\n",
    "T = 1.0  # Total time\n",
    "alpha = 0.1  # Thermal diffusivity\n",
    "\n",
    "# Boundary and initial conditions\n",
    "T_top, T_bottom = 303.15, 303.15\n",
    "T_left, T_right = 274.15, 274.15\n",
    "T_init = 295.65\n",
    "\n",
    "Pb_top, Pb_bottom = 1e7, 1e7\n",
    "Pb_left, Pb_right = 1e6, 1e6\n",
    "Pb_init = 1e7\n",
    "\n",
    "CAb_top, CAb_bottom = 1.0, 1.0\n",
    "CAb_left, CAb_right = 0.94, 0.94\n",
    "CAb_init = 0.94\n",
    "\n",
    "Af = 5.8446E5\n",
    "Ac = 5.8264E8\n",
    "Eaf = 75400\n",
    "Eac = 1.038E5\n",
    "aa = 0.27\n",
    "R = 8.314  # Gas constant in J/(molÂ·K)\n",
    "\n",
    "# Calculate scaling factors\n",
    "T_min, T_max = min(T_left, T_right, T_bottom, T_top, T_init), max(T_left, T_right, T_bottom, T_top, T_init)\n",
    "Pb_min, Pb_max = min(Pb_left, Pb_right, Pb_bottom, Pb_top, Pb_init), max(Pb_left, Pb_right, Pb_bottom, Pb_top, Pb_init)\n",
    "CAb_min, CAb_max = min(CAb_left, CAb_right, CAb_bottom, CAb_top, CAb_init), max(CAb_left, CAb_right, CAb_bottom, CAb_top, CAb_init)\n",
    "\n",
    "# Scaling functions\n",
    "def scale_var(var, var_min, var_max):\n",
    "    return (var - var_min) / (var_max - var_min)\n",
    "\n",
    "def unscale_var(var_scaled, var_min, var_max):\n",
    "    return var_scaled * (var_max - var_min) + var_min\n",
    "\n",
    "# Scale the boundary and initial conditions\n",
    "T_top_scaled, T_bottom_scaled = scale_var(T_top, T_min, T_max), scale_var(T_bottom, T_min, T_max)\n",
    "T_left_scaled, T_right_scaled = scale_var(T_left, T_min, T_max), scale_var(T_right, T_min, T_max)\n",
    "T_init_scaled = scale_var(T_init, T_min, T_max)\n",
    "\n",
    "Pb_top_scaled, Pb_bottom_scaled = scale_var(Pb_top, Pb_min, Pb_max), scale_var(Pb_bottom, Pb_min, Pb_max)\n",
    "Pb_left_scaled, Pb_right_scaled = scale_var(Pb_left, Pb_min, Pb_max), scale_var(Pb_right, Pb_min, Pb_max)\n",
    "Pb_init_scaled = scale_var(Pb_init, Pb_min, Pb_max)\n",
    "\n",
    "CAb_top_scaled, CAb_bottom_scaled = scale_var(CAb_top, CAb_min, CAb_max), scale_var(CAb_bottom, CAb_min, CAb_max)\n",
    "CAb_left_scaled, CAb_right_scaled = scale_var(CAb_left, CAb_min, CAb_max), scale_var(CAb_right, CAb_min, CAb_max)\n",
    "CAb_init_scaled = scale_var(CAb_init, CAb_min, CAb_max)\n",
    "\n",
    "# PINN model\n",
    "class CoupledPINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 10),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, stage):\n",
    "        output = self.net(x)\n",
    "        if stage == 1:\n",
    "            return output[:, 0:1]  # Only temperature\n",
    "        elif stage == 2:\n",
    "            return output[:, 0:2]  # Temperature and oxygen pressure\n",
    "        else:\n",
    "            return output  # All three variables\n",
    "\n",
    "# PDE residual\n",
    "def pde_residual(model, x, y, t, stage):\n",
    "    xyts = torch.cat([x, y, t], dim=1)\n",
    "    xyts.requires_grad_(True)\n",
    "    \n",
    "    output = model(xyts, stage)\n",
    "    \n",
    "    if stage == 1:\n",
    "        T = output\n",
    "        grads = torch.autograd.grad(T, xyts, grad_outputs=torch.ones_like(T), create_graph=True)[0]\n",
    "        T_t, T_x, T_y = grads[:, 2:3], grads[:, 0:1], grads[:, 1:2]\n",
    "        T_xx = torch.autograd.grad(T_x, xyts, grad_outputs=torch.ones_like(T_x), create_graph=True)[0][:, 0:1]\n",
    "        T_yy = torch.autograd.grad(T_y, xyts, grad_outputs=torch.ones_like(T_y), create_graph=True)[0][:, 1:2]\n",
    "        res_T = T_t - alpha * (T_xx + T_yy)\n",
    "        return res_T\n",
    "    \n",
    "    elif stage == 2:\n",
    "        T, Pb = output[:, 0:1], output[:, 1:2]\n",
    "        grads = torch.autograd.grad(output, xyts, grad_outputs=torch.ones_like(output), create_graph=True)[0]\n",
    "        T_t, Pb_t = grads[:, 2:3], grads[:, 2:3]\n",
    "        T_x, Pb_x = grads[:, 0:1], grads[:, 0:1]\n",
    "        T_y, Pb_y = grads[:, 1:2], grads[:, 1:2]\n",
    "        T_xx = torch.autograd.grad(T_x, xyts, grad_outputs=torch.ones_like(T_x), create_graph=True)[0][:, 0:1]\n",
    "        T_yy = torch.autograd.grad(T_y, xyts, grad_outputs=torch.ones_like(T_y), create_graph=True)[0][:, 1:2]\n",
    "        Pb_xx = torch.autograd.grad(Pb_x, xyts, grad_outputs=torch.ones_like(Pb_x), create_graph=True)[0][:, 0:1]\n",
    "        Pb_yy = torch.autograd.grad(Pb_y, xyts, grad_outputs=torch.ones_like(Pb_y), create_graph=True)[0][:, 1:2]\n",
    "        res_T = T_t - alpha * (T_xx + T_yy)\n",
    "        res_Pb = Pb_t - (1E-11 * (Pb_xx + Pb_yy))  # Simplified oxygen pressure equation\n",
    "        return res_T, res_Pb\n",
    "    \n",
    "    else:\n",
    "        T, Pb, CAb = output[:, 0:1], output[:, 1:2], output[:, 2:3]\n",
    "        T = torch.clamp(T, min=1e-6)  # Avoid negative temperatures\n",
    "        Pb = torch.clamp(Pb, min=1e-6)  # Avoid negative pressures\n",
    "        grads = torch.autograd.grad(output, xyts, grad_outputs=torch.ones_like(output), create_graph=True)[0]\n",
    "        T_t, Pb_t, CAb_t = grads[:, 2:3], grads[:, 2:3], grads[:, 2:3]\n",
    "        T_x, Pb_x = grads[:, 0:1], grads[:, 0:1]\n",
    "        T_y, Pb_y = grads[:, 1:2], grads[:, 1:2]\n",
    "        T_xx = torch.autograd.grad(T_x, xyts, grad_outputs=torch.ones_like(T_x), create_graph=True)[0][:, 0:1]\n",
    "        T_yy = torch.autograd.grad(T_y, xyts, grad_outputs=torch.ones_like(T_y), create_graph=True)[0][:, 1:2]\n",
    "        Pb_xx = torch.autograd.grad(Pb_x, xyts, grad_outputs=torch.ones_like(Pb_x), create_graph=True)[0][:, 0:1]\n",
    "        Pb_yy = torch.autograd.grad(Pb_y, xyts, grad_outputs=torch.ones_like(Pb_y), create_graph=True)[0][:, 1:2]\n",
    "        \n",
    "        # Calculate kf and kc\n",
    "        kf = Af * (Pb/101325)**aa * torch.exp(-Eaf/(R*T)) * 1E7\n",
    "        kc = Ac * (Pb/101325)**aa * torch.exp(-Eac/(R*T)) * 1E7\n",
    "        \n",
    "        res_T = T_t - alpha * (T_xx + T_yy)\n",
    "        res_Pb = Pb_t - (1E-11 * (Pb_xx + Pb_yy)) + (((8.3 * T)) * CAb_t)  # Simplified coupled equations\n",
    "        res_CAb = CAb_t - (0.05 * kf * torch.exp(-kf * t) + kc)  # Updated carbonyl area equation\n",
    "        return res_T, res_Pb, res_CAb\n",
    "\n",
    "# Loss function\n",
    "def curriculum_coupled_pinn_loss(model, x, y, t, x_bc, y_bc, t_bc, T_bc, Pb_bc, CAb_bc, x_ic, y_ic, t_ic, T_ic, Pb_ic, CAb_ic, stage):\n",
    "    # Predict boundary and initial conditions\n",
    "    bc_pred = model(torch.cat([x_bc, y_bc, t_bc], dim=1), stage)\n",
    "    ic_pred = model(torch.cat([x_ic, y_ic, t_ic], dim=1), stage)\n",
    "    \n",
    "    mse_loss = nn.MSELoss()\n",
    "    \n",
    "    if stage == 1:\n",
    "        T_bc_pred = bc_pred\n",
    "        T_ic_pred = ic_pred\n",
    "        loss_bc = mse_loss(T_bc_pred, T_bc)\n",
    "        loss_ic = mse_loss(T_ic_pred, T_ic)\n",
    "        res_T = pde_residual(model, x, y, t, stage)\n",
    "        loss_pde = torch.mean(torch.square(res_T))\n",
    "    elif stage == 2:\n",
    "        T_bc_pred, Pb_bc_pred = bc_pred[:, 0:1], bc_pred[:, 1:2]\n",
    "        T_ic_pred, Pb_ic_pred = ic_pred[:, 0:1], ic_pred[:, 1:2]\n",
    "        loss_bc = mse_loss(T_bc_pred, T_bc) + mse_loss(Pb_bc_pred, Pb_bc)\n",
    "        loss_ic = mse_loss(T_ic_pred, T_ic) + mse_loss(Pb_ic_pred, Pb_ic)\n",
    "        res_T, res_Pb = pde_residual(model, x, y, t, stage)\n",
    "        loss_pde = torch.mean(torch.square(res_T) + torch.square(res_Pb))\n",
    "    else:\n",
    "        T_bc_pred, Pb_bc_pred, CAb_bc_pred = bc_pred[:, 0:1], bc_pred[:, 1:2], bc_pred[:, 2:3]\n",
    "        T_ic_pred, Pb_ic_pred, CAb_ic_pred = ic_pred[:, 0:1], ic_pred[:, 1:2], ic_pred[:, 2:3]\n",
    "        loss_bc = mse_loss(T_bc_pred, T_bc) + mse_loss(Pb_bc_pred, Pb_bc) + mse_loss(CAb_bc_pred, CAb_bc)\n",
    "        loss_ic = mse_loss(T_ic_pred, T_ic) + mse_loss(Pb_ic_pred, Pb_ic) + mse_loss(CAb_ic_pred, CAb_ic)\n",
    "        res_T, res_Pb, res_CAb = pde_residual(model, x, y, t, stage)\n",
    "        loss_pde = torch.mean(torch.square(res_T) + torch.square(res_Pb) + torch.square(res_CAb))\n",
    "    \n",
    "    total_loss = loss_bc + loss_ic + loss_pde\n",
    "    return total_loss, {'bc': loss_bc.item(), 'ic': loss_ic.item(), 'pde': loss_pde.item()}\n",
    "\n",
    "# Generate collocation points\n",
    "def generate_collocation_points(n_points, L_x, L_y, T):\n",
    "    x = torch.rand(n_points, 1) * L_x\n",
    "    y = torch.rand(n_points, 1) * L_y\n",
    "    t = torch.rand(n_points, 1) * T\n",
    "    return x, y, t\n",
    "\n",
    "# Generate boundary condition data\n",
    "def generate_bc_data(n_points, L_x, L_y, T):\n",
    "    # Top and bottom edges\n",
    "    x_tb = torch.rand(n_points // 2, 1) * L_x\n",
    "    y_top = torch.full_like(x_tb, L_y)\n",
    "    y_bottom = torch.zeros_like(x_tb)\n",
    "    t_tb = torch.rand(n_points // 2, 1) * T\n",
    "    \n",
    "    # Left and right edges\n",
    "    y_lr = torch.rand(n_points // 2, 1) * L_y\n",
    "    x_left = torch.zeros_like(y_lr)\n",
    "    x_right = torch.full_like(y_lr, L_x)\n",
    "    t_lr = torch.rand(n_points // 2, 1) * T\n",
    "    \n",
    "    x_bc = torch.cat([x_tb, x_tb, x_left, x_right], dim=0)\n",
    "    y_bc = torch.cat([y_top, y_bottom, y_lr, y_lr], dim=0)\n",
    "    t_bc = torch.cat([t_tb, t_tb, t_lr, t_lr], dim=0)\n",
    "    \n",
    "    T_bc = torch.cat([\n",
    "        torch.full_like(x_tb, T_top_scaled),\n",
    "        torch.full_like(x_tb, T_bottom_scaled),\n",
    "        torch.full_like(y_lr, T_left_scaled),\n",
    "        torch.full_like(y_lr, T_right_scaled)\n",
    "    ], dim=0)\n",
    "    \n",
    "    Pb_bc = torch.cat([\n",
    "        torch.full_like(x_tb, Pb_top_scaled),\n",
    "        torch.full_like(x_tb, Pb_bottom_scaled),\n",
    "        torch.full_like(y_lr, Pb_left_scaled),\n",
    "        torch.full_like(y_lr, Pb_right_scaled)\n",
    "    ], dim=0)\n",
    "    \n",
    "    CAb_bc = torch.cat([\n",
    "        torch.full_like(x_tb, CAb_top_scaled),\n",
    "        torch.full_like(x_tb, CAb_bottom_scaled),\n",
    "        torch.full_like(y_lr, CAb_left_scaled),\n",
    "        torch.full_like(y_lr, CAb_right_scaled)\n",
    "    ], dim=0)\n",
    "    \n",
    "    return x_bc, y_bc, t_bc, T_bc, Pb_bc, CAb_bc\n",
    "\n",
    "# Generate initial condition data\n",
    "def generate_ic_data(n_points, L_x, L_y):\n",
    "    x_ic = torch.rand(n_points, 1) * L_x\n",
    "    y_ic = torch.rand(n_points, 1) * L_y\n",
    "    t_ic = torch.zeros_like(x_ic)\n",
    "    T_ic = torch.full_like(x_ic, T_init_scaled)\n",
    "    Pb_ic = torch.full_like(x_ic, Pb_init_scaled)\n",
    "    CAb_ic = torch.full_like(x_ic, CAb_init_scaled)\n",
    "    \n",
    "    return x_ic, y_ic, t_ic, T_ic, Pb_ic, CAb_ic\n",
    "\n",
    "# Create heatmap data\n",
    "def create_heatmap_data(model, t_values, stage, nx=100, ny=100):\n",
    "    x = torch.linspace(0, L_x, nx).unsqueeze(1)\n",
    "    y = torch.linspace(0, L_y, ny).unsqueeze(1)\n",
    "    X, Y = torch.meshgrid(x.squeeze(), y.squeeze(), indexing='ij')\n",
    "    \n",
    "    xy = torch.column_stack((X.reshape(-1, 1), Y.reshape(-1, 1)))\n",
    "    \n",
    "    results = []\n",
    "    for t in t_values:\n",
    "        t_array = torch.full((nx*ny, 1), t)\n",
    "        input_data = torch.cat((xy, t_array), dim=1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_data, stage)\n",
    "            if stage == 1:\n",
    "                T_scaled = output.reshape(nx, ny)\n",
    "                T_pinn = unscale_var(T_scaled, T_min, T_max)\n",
    "                results.append((T_pinn.numpy(), None, None))\n",
    "            elif stage == 2:\n",
    "                T_scaled, Pb_scaled = output[:, 0].reshape(nx, ny), output[:, 1].reshape(nx, ny)\n",
    "                T_pinn = unscale_var(T_scaled, T_min, T_max)\n",
    "                Pb_pinn = unscale_var(Pb_scaled, Pb_min, Pb_max)\n",
    "                results.append((T_pinn.numpy(), Pb_pinn.numpy(), None))\n",
    "            else:\n",
    "                T_scaled, Pb_scaled, CAb_scaled = output[:, 0].reshape(nx, ny), output[:, 1].reshape(nx, ny), output[:, 2].reshape(nx, ny)\n",
    "                T_pinn = unscale_var(T_scaled, T_min, T_max)\n",
    "                Pb_pinn = unscale_var(Pb_scaled, Pb_min, Pb_max)\n",
    "                CAb_pinn = unscale_var(CAb_scaled, CAb_min, CAb_max)\n",
    "                results.append((T_pinn.numpy(), Pb_pinn.numpy(), CAb_pinn.numpy()))\n",
    "    \n",
    "    return X.numpy(), Y.numpy(), results\n",
    "\n",
    "def plot_heatmaps(X, Y, results, stage, epoch):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    variables = [\n",
    "        (\"Temperature (K)\", 0),\n",
    "        (\"Oxygen Pressure (Pa)\", 1),\n",
    "        (\"Carbonyl Area\", 2)\n",
    "    ]\n",
    "    \n",
    "    for i, (title, idx) in enumerate(variables):\n",
    "        for j, (t, result) in enumerate(zip([0, 1], results)):\n",
    "            var = result[idx]\n",
    "            if var is not None:\n",
    "                im = axes[j, i].imshow(var.T, extent=[0, L_x, 0, L_y], origin='lower', cmap='turbo', aspect='auto')\n",
    "                axes[j, i].set_title(f'PINN {title} (t={t})')\n",
    "                plt.colorbar(im, ax=axes[j, i], label=title)\n",
    "            else:\n",
    "                axes[j, i].text(0.5, 0.5, \"Not Available\", ha='center', va='center')\n",
    "                axes[j, i].set_title(f'{title} (t={t}, Not Available)')\n",
    "            axes[j, i].set_xlabel('x')\n",
    "            axes[j, i].set_ylabel('y')\n",
    "    \n",
    "    plt.suptitle(f'Stage {stage}, Epoch {epoch}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'heatmap_stage_{stage}_epoch_{epoch}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Implement curriculum learning\n",
    "def train_coupled_pinn_curriculum(model, epochs_per_stage=100000, plot_every=2000):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    all_losses = {'pde': [], 'bc': [], 'ic': [], 'total': []}\n",
    "    \n",
    "    for stage in range(1, 4):\n",
    "        print(f\"Starting curriculum stage {stage}\")\n",
    "        \n",
    "        # Adjust domain complexity based on the stage\n",
    "        L_x_stage = L_x * stage / 3\n",
    "        L_y_stage = L_y * stage / 3\n",
    "        T_stage = T * stage / 3\n",
    "        \n",
    "        # Generate training data for the current stage\n",
    "        n_points = 1000\n",
    "        x_train, y_train, t_train = generate_collocation_points(n_points, L_x_stage, L_y_stage, T_stage)\n",
    "        x_bc, y_bc, t_bc, T_bc, Pb_bc, CAb_bc = generate_bc_data(n_points, L_x_stage, L_y_stage, T_stage)\n",
    "        x_ic, y_ic, t_ic, T_ic, Pb_ic, CAb_ic = generate_ic_data(n_points, L_x_stage, L_y_stage)\n",
    "        \n",
    "        for epoch in range(epochs_per_stage):\n",
    "            optimizer.zero_grad()\n",
    "            loss, component_losses = curriculum_coupled_pinn_loss(\n",
    "                model, x_train, y_train, t_train, \n",
    "                x_bc, y_bc, t_bc, T_bc, Pb_bc, CAb_bc, \n",
    "                x_ic, y_ic, t_ic, T_ic, Pb_ic, CAb_ic,\n",
    "                stage\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Store loss values\n",
    "            all_losses['pde'].append(component_losses['pde'])\n",
    "            all_losses['bc'].append(component_losses['bc'])\n",
    "            all_losses['ic'].append(component_losses['ic'])\n",
    "            all_losses['total'].append(loss.item())\n",
    "            \n",
    "            if epoch % plot_every == 0:\n",
    "                print(f\"Stage {stage}, Epoch {epoch}, Total Loss: {loss.item():.4f}\")\n",
    "                print(f\"Component Losses - BC: {component_losses['bc']:.4f}, IC: {component_losses['ic']:.4f}, PDE: {component_losses['pde']:.4f}\")\n",
    "                \n",
    "                # Create and plot heatmaps for t=0 and t=T_stage\n",
    "                X, Y, results = create_heatmap_data(model, [0, T_stage], stage)\n",
    "                plot_heatmaps(X, Y, results, stage, epoch)\n",
    "    \n",
    "    return model, all_losses\n",
    "\n",
    "# Add a new function to plot the losses\n",
    "def plot_losses(all_losses):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    epochs = range(1, len(all_losses['total']) + 1)\n",
    "    \n",
    "    for loss_type in ['pde', 'bc', 'ic', 'total']:\n",
    "        plt.plot(epochs, all_losses[loss_type], label=f'{loss_type.upper()} Loss')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Losses')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Determine if log scale is better\n",
    "    if max(all_losses['total']) / min(all_losses['total']) > 100:\n",
    "        plt.yscale('log')\n",
    "        plt.title('Training Losses (Log Scale)')\n",
    "    \n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_losses.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# \n",
    "\n",
    "def generate_line_predictions(model, L_x, L_y, T, nx=100, ny=100):\n",
    "    # Generate points along horizontal and vertical lines\n",
    "    x_horizontal = torch.linspace(0, L_x, nx).unsqueeze(1)\n",
    "    y_horizontal = torch.full_like(x_horizontal, L_y / 2)\n",
    "    \n",
    "    y_vertical = torch.linspace(0, L_y, ny).unsqueeze(1)\n",
    "    x_vertical = torch.full_like(y_vertical, L_x / 2)\n",
    "    \n",
    "    # Generate time points\n",
    "    t_0 = torch.zeros_like(x_horizontal)\n",
    "    t_1 = torch.full_like(x_horizontal, T)\n",
    "    \n",
    "    # Combine inputs for horizontal and vertical lines at t=0 and t=1\n",
    "    inputs_horizontal_0 = torch.cat((x_horizontal, y_horizontal, t_0), dim=1)\n",
    "    inputs_horizontal_1 = torch.cat((x_horizontal, y_horizontal, t_1), dim=1)\n",
    "    inputs_vertical_0 = torch.cat((x_vertical, y_vertical, t_0), dim=1)\n",
    "    inputs_vertical_1 = torch.cat((x_vertical, y_vertical, t_1), dim=1)\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs_horizontal_0 = model(inputs_horizontal_0, stage=3)\n",
    "        outputs_horizontal_1 = model(inputs_horizontal_1, stage=3)\n",
    "        outputs_vertical_0 = model(inputs_vertical_0, stage=3)\n",
    "        outputs_vertical_1 = model(inputs_vertical_1, stage=3)\n",
    "    \n",
    "    # Unscale the predictions\n",
    "    T_horizontal_0 = unscale_var(outputs_horizontal_0[:, 0], T_min, T_max)\n",
    "    Pb_horizontal_0 = unscale_var(outputs_horizontal_0[:, 1], Pb_min, Pb_max)\n",
    "    CAb_horizontal_0 = unscale_var(outputs_horizontal_0[:, 2], CAb_min, CAb_max)\n",
    "    \n",
    "    T_horizontal_1 = unscale_var(outputs_horizontal_1[:, 0], T_min, T_max)\n",
    "    Pb_horizontal_1 = unscale_var(outputs_horizontal_1[:, 1], Pb_min, Pb_max)\n",
    "    CAb_horizontal_1 = unscale_var(outputs_horizontal_1[:, 2], CAb_min, CAb_max)\n",
    "    \n",
    "    T_vertical_0 = unscale_var(outputs_vertical_0[:, 0], T_min, T_max)\n",
    "    Pb_vertical_0 = unscale_var(outputs_vertical_0[:, 1], Pb_min, Pb_max)\n",
    "    CAb_vertical_0 = unscale_var(outputs_vertical_0[:, 2], CAb_min, CAb_max)\n",
    "    \n",
    "    T_vertical_1 = unscale_var(outputs_vertical_1[:, 0], T_min, T_max)\n",
    "    Pb_vertical_1 = unscale_var(outputs_vertical_1[:, 1], Pb_min, Pb_max)\n",
    "    CAb_vertical_1 = unscale_var(outputs_vertical_1[:, 2], CAb_min, CAb_max)\n",
    "    \n",
    "    return {\n",
    "        'horizontal_0': (x_horizontal.numpy(), T_horizontal_0.numpy(), Pb_horizontal_0.numpy(), CAb_horizontal_0.numpy()),\n",
    "        'horizontal_1': (x_horizontal.numpy(), T_horizontal_1.numpy(), Pb_horizontal_1.numpy(), CAb_horizontal_1.numpy()),\n",
    "        'vertical_0': (y_vertical.numpy(), T_vertical_0.numpy(), Pb_vertical_0.numpy(), CAb_vertical_0.numpy()),\n",
    "        'vertical_1': (y_vertical.numpy(), T_vertical_1.numpy(), Pb_vertical_1.numpy(), CAb_vertical_1.numpy())\n",
    "    }\n",
    "\n",
    "def create_excel_file(predictions, filename='predictions.xlsx'):\n",
    "    wb = Workbook()\n",
    "    \n",
    "    # Create sheets\n",
    "    sheets = {\n",
    "        'Horizontal t=0': (predictions['horizontal_0'], 'x'),\n",
    "        'Horizontal t=1': (predictions['horizontal_1'], 'x'),\n",
    "        'Vertical t=0': (predictions['vertical_0'], 'y'),\n",
    "        'Vertical t=1': (predictions['vertical_1'], 'y')\n",
    "    }\n",
    "    \n",
    "    for sheet_name, (data, coordinate) in sheets.items():\n",
    "        if sheet_name in wb.sheetnames:\n",
    "            sheet = wb[sheet_name]\n",
    "        else:\n",
    "            sheet = wb.create_sheet(sheet_name)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            coordinate: data[0].flatten(),\n",
    "            'Temperature (K)': data[1].flatten(),\n",
    "            'Oxygen Pressure (Pa)': data[2].flatten(),\n",
    "            'Carbonyl Area': data[3].flatten()\n",
    "        })\n",
    "        \n",
    "        for row in dataframe_to_rows(df, index=False, header=True):\n",
    "            sheet.append(row)\n",
    "    \n",
    "    # Remove the default sheet created by openpyxl\n",
    "    if 'Sheet' in wb.sheetnames:\n",
    "        wb.remove(wb['Sheet'])\n",
    "    \n",
    "    wb.save(filename)\n",
    "    print(f\"Excel file '{filename}' has been created.\")\n",
    "\n",
    "\n",
    "#Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Create coupled PINN model\n",
    "    coupled_pinn_model = CoupledPINN()\n",
    "    \n",
    "    # Train the model using curriculum learning and get the losses\n",
    "    trained_model, all_losses = train_coupled_pinn_curriculum(coupled_pinn_model, epochs_per_stage=100000, plot_every=2000)\n",
    "    \n",
    "    # Plot the losses\n",
    "    plot_losses(all_losses)\n",
    "    \n",
    "    # Generate validation data\n",
    "    n_points = 1000\n",
    "    x_val, y_val, t_val = generate_collocation_points(n_points, L_x, L_y, T)\n",
    "    X_val = torch.cat([x_val, y_val, t_val], dim=1)\n",
    "    \n",
    "    # PINN predictions on validation data\n",
    "    with torch.no_grad():\n",
    "        pinn_pred = trained_model(X_val, stage=3).numpy()\n",
    "        T_pinn = unscale_var(pinn_pred[:, 0], T_min, T_max)\n",
    "        Pb_pinn = unscale_var(pinn_pred[:, 1], Pb_min, Pb_max)\n",
    "        CAb_pinn = unscale_var(pinn_pred[:, 2], CAb_min, CAb_max)\n",
    "    \n",
    "    # Calculate PDE residuals for GP training\n",
    "    res_T, res_Pb, res_CAb = pde_residual(trained_model, x_val, y_val, t_val, stage=3)\n",
    "    residuals = torch.cat([res_T, res_Pb, res_CAb], dim=1).detach().numpy()\n",
    "    \n",
    "    # Preprocess the input data and residuals\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    X_val_scaled = scaler_X.fit_transform(X_val.numpy())\n",
    "    residuals_scaled = scaler_y.fit_transform(residuals)\n",
    "\n",
    "    kernel = 1.0 * RBF(length_scale=[1.0] * X_val_scaled.shape[1]) + WhiteKernel(noise_level=1e-5)\n",
    "    \n",
    "    # Train GP on PDE residuals with optimized settings\n",
    "    gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        n_restarts_optimizer=5,\n",
    "        normalize_y=False,  # We're manually scaling\n",
    "        random_state=42,\n",
    "        alpha=1e-10,\n",
    "        optimizer='fmin_l_bfgs_b',\n",
    "    )\n",
    "    \n",
    "    gp.fit(X_val_scaled, residuals_scaled)\n",
    "    \n",
    "    # Predict residuals using GP\n",
    "    X_val_full_scaled = scaler_X.transform(X_val.numpy())\n",
    "    residuals_gp_scaled, std_gp_scaled = gp.predict(X_val_full_scaled, return_std=True)\n",
    "    \n",
    "    # Unscale the predictions\n",
    "    residuals_gp = scaler_y.inverse_transform(residuals_gp_scaled)\n",
    "    std_gp = std_gp_scaled * scaler_y.scale_\n",
    "    \n",
    "    # Combine PINN and GP predictions\n",
    "    T_combined = T_pinn - residuals_gp[:, 0]\n",
    "    Pb_combined = Pb_pinn - residuals_gp[:, 1]\n",
    "    CAb_combined = CAb_pinn - residuals_gp[:, 2]\n",
    "    \n",
    "    # Print GP kernel parameters\n",
    "    print(\"\\nOptimized GP Kernel:\")\n",
    "    print(gp.kernel_)\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    mse_T_pinn = np.mean((T_pinn - T_init)**2)\n",
    "    mse_T_combined = np.mean((T_combined - T_init)**2)\n",
    "    mse_Pb_pinn = np.mean((Pb_pinn - Pb_init)**2)\n",
    "    mse_Pb_combined = np.mean((Pb_combined - Pb_init)**2)\n",
    "    mse_CAb_pinn = np.mean((CAb_pinn - CAb_init)**2)\n",
    "    mse_CAb_combined = np.mean((CAb_combined - CAb_init)**2)\n",
    "    \n",
    "    print(f\"MSE Temperature PINN: {mse_T_pinn:.6f}\")\n",
    "    print(f\"MSE Temperature PINN+GP: {mse_T_combined:.6f}\")\n",
    "    print(f\"MSE Oxygen Pressure PINN: {mse_Pb_pinn:.6f}\")\n",
    "    print(f\"MSE Oxygen Pressure PINN+GP: {mse_Pb_combined:.6f}\")\n",
    "    print(f\"MSE Carbonyl Area PINN: {mse_CAb_pinn:.6f}\")\n",
    "    print(f\"MSE Carbonyl Area PINN+GP: {mse_CAb_combined:.6f}\")\n",
    "\n",
    "\n",
    "    # Generate predictions along lines\n",
    "    predictions = generate_line_predictions(trained_model, L_x, L_y, T)\n",
    "    \n",
    "    # Create Excel file with predictions\n",
    "    create_excel_file(predictions)\n",
    "\n",
    "    \n",
    "    # Create and plot final heatmaps\n",
    "    X, Y, results = create_heatmap_data(trained_model, [0, T], stage=3)\n",
    "    plot_heatmaps(X, Y, results, stage=3, epoch=\"Final\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_and_plot_pinn_gp_heatmaps(trained_model, gp, scaler_X, scaler_y, t_values, stage, nx=100, ny=100):\n",
    "    x = np.linspace(0, L_x, nx)\n",
    "    y = np.linspace(0, L_y, ny)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    for t_idx, t in enumerate(t_values):\n",
    "        xy = np.column_stack((X.flatten(), Y.flatten()))\n",
    "        t_array = np.full((nx*ny, 1), t)\n",
    "        input_data = np.hstack((xy, t_array))\n",
    "        \n",
    "        # PINN predictions\n",
    "        with torch.no_grad():\n",
    "            pinn_pred = trained_model(torch.tensor(input_data).float(), stage).numpy()\n",
    "        \n",
    "        # Unscale PINN predictions\n",
    "        T_pinn = unscale_var(pinn_pred[:, 0], T_min, T_max)\n",
    "        Pb_pinn = unscale_var(pinn_pred[:, 1], Pb_min, Pb_max)\n",
    "        CAb_pinn = unscale_var(pinn_pred[:, 2], CAb_min, CAb_max)\n",
    "        \n",
    "        # GP corrections\n",
    "        input_data_scaled = scaler_X.transform(input_data)\n",
    "        residuals_gp_scaled, _ = gp.predict(input_data_scaled, return_std=True)\n",
    "        residuals_gp = scaler_y.inverse_transform(residuals_gp_scaled)\n",
    "        \n",
    "        # Combine PINN and GP predictions\n",
    "        T_combined = T_pinn - residuals_gp[:, 0]\n",
    "        Pb_combined = Pb_pinn - residuals_gp[:, 1]\n",
    "        CAb_combined = CAb_pinn - residuals_gp[:, 2]\n",
    "        \n",
    "        variables = [\n",
    "            (\"Temperature (K)\", T_combined),\n",
    "            (\"Oxygen Pressure (Pa)\", Pb_combined),\n",
    "            (\"Carbonyl Area\", CAb_combined)\n",
    "        ]\n",
    "        \n",
    "        for i, (title, var) in enumerate(variables):\n",
    "            im = axes[t_idx, i].imshow(var.reshape(nx, ny).T, extent=[0, L_x, 0, L_y], origin='lower', cmap='turbo', aspect='auto')\n",
    "            axes[t_idx, i].set_title(f'PINN+GP {title} (t={t})')\n",
    "            plt.colorbar(im, ax=axes[t_idx, i], label=title)\n",
    "            axes[t_idx, i].set_xlabel('x')\n",
    "            axes[t_idx, i].set_ylabel('y')\n",
    "    \n",
    "    plt.suptitle(f'PINN+GP Predictions, Stage {stage}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'heatmap_pinn_gp_stage_{stage}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Usage\n",
    "create_and_plot_pinn_gp_heatmaps(trained_model, gp, scaler_X, scaler_y, [0, T], stage=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
